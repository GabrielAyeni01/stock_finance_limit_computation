{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7b081ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "##########     IMPORT NECESSARY LIBRARIES.   ###########################\n",
    "########################################################################\n",
    "from msal import ConfidentialClientApplication\n",
    "import imaplib\n",
    "import email\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import timedelta,datetime\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "import oracledb as orc\n",
    "import csv\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "#from statsmodels.tsa.api import ExponentialSmoothing\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' %x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a402d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "##########     CREATE CLASS FOR INSERTING INTO DB.   ###################\n",
    "########################################################################\n",
    "class DataMigration:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def writePandas(self,table_name,\n",
    "                 columns,sourcedataframe,batch_size = 10000,\n",
    "                 renamed_columns={}):\n",
    "        currrow=None\n",
    "        try:\n",
    "            # c = props.ProcessDataDbToFile()\n",
    "            # conn = c.get_db_conn()\n",
    "            pddata=sourcedataframe\n",
    "            pddata.rename(columns=renamed_columns, inplace=True)\n",
    "            print(pddata.shape)\n",
    "            print(pddata.head(3))\n",
    "            \n",
    "            connection = orc.connect(user='', password='', dsn='')\n",
    "            with connection.cursor() as cur:\n",
    "                i=0\n",
    "                colnanmesstr=\"(\"\n",
    "                placeholder=\"(\"\n",
    "                for col in columns:\n",
    "                    if i==0:\n",
    "                        placeholder=placeholder+\":v\"+str(i)\n",
    "                        colnanmesstr = colnanmesstr + col\n",
    "                    else:\n",
    "                        placeholder = placeholder + \",:v\" + str(i)\n",
    "                        colnanmesstr = colnanmesstr + \",\" + col\n",
    "                    i=i+1\n",
    "                placeholder = placeholder + \")\"\n",
    "                colnanmesstr=colnanmesstr+\")\"\n",
    "                sql = f\"\"\"insert into {table_name} {colnanmesstr} values {placeholder}\"\"\"\n",
    "                insertdata = []\n",
    "                try:\n",
    "\n",
    "                    # Predefine the memory areas to match the table definition\n",
    "                    cur.setinputsizes(None, 25)\n",
    "                    # Adjust the batch size to meet your memory and performance requirements\n",
    "                    # batch_size = 10000\n",
    "                    for record in pddata.itertuples(index=False):\n",
    "                        row=record._asdict()\n",
    "                        record_insert = tuple(row[col] for col in columns)\n",
    "                        # print(record_insert)\n",
    "                        insertdata.append(record_insert)\n",
    "                        if len(insertdata) % batch_size == 0:\n",
    "                            # print(insertdata)\n",
    "                            cur.executemany(sql, insertdata)\n",
    "                            insertdata = []\n",
    "                            connection.commit()\n",
    "                        # print(row)\n",
    "                    if insertdata:\n",
    "                        cur.executemany(sql, insertdata)\n",
    "                    connection.commit()\n",
    "                    # conn.close()\n",
    "                    print(\"end---\",pddata.shape)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(insertdata)\n",
    "                    raise e\n",
    "        except Exception as e:\n",
    "            print(\"overall\",e)\n",
    "            # conn.rollback()\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9fbd289",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "##########     CLIENT SECRET FOR OUTLOOK ACCESS   ######################\n",
    "########################################################################\n",
    "def get_access_token():\n",
    "    tenantID = 'd763f040-5b2c-4d8f-9810-95b011cd8254'\n",
    "    authority = 'https://login.microsoftonline.com/' + tenantID\n",
    "    clientID = '6afa9b7a-a61f-4060-89d6-db33c0ea74d0'\n",
    "    clientSecret = 'VNd8Q~txHU6yWVBGeRBgLOXbdGZNQrWkavJptbre'\n",
    "    scope = ['https://outlook.office365.com/.default'\n",
    "             #'https://graph.microsoft.com/IMAP.AccessAsUser.All/.default'\n",
    "             #'https://ps.outlook.com/IMAP.AccessAsApp/.default'\n",
    "             #'https://outlook.office365.com/IMAP.AccessAsApp/.default'\n",
    "            #'https://outlook.office.com/POP.AccessAsUser.All',\n",
    "             #'api://6afa9b7a-a61f-4060-89d6-db33c0ea74d0/IMAP'\n",
    "            #'https://outlook.office.com/SMTP.Send']\n",
    "    ]\n",
    "    app = ConfidentialClientApplication(clientID, \n",
    "          authority=authority, \n",
    "          client_credential = clientSecret)\n",
    "    access_token = app.acquire_token_for_client(scopes=scope)\n",
    "    return access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09a3bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "##########     TOKEN GENERATION TO ACCESS INBOX  #######################\n",
    "########################################################################\n",
    "def generate_auth_string(user, token):\n",
    "    auth_string = f\"user={user}\\1auth=Bearer {token}\\1\\1\"\n",
    "    return auth_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c422252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  36:37.79 > b'LKIH1 AUTHENTICATE XOAUTH2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'unauthorized_client', 'error_description': \"AADSTS700016: Application with identifier '6afa9b7a-a61f-4060-89d6-db33c0ea74d0' was not found in the directory 'I&M Bank Limited'. This can happen if the application has not been installed by the administrator of the tenant or consented to by any user in the tenant. You may have sent your authentication request to the wrong tenant. Trace ID: 66f7bffc-ea95-42f9-a58a-c93509898c00 Correlation ID: 74ffddbb-c8c9-40d7-b7cf-a68c1552e9ac Timestamp: 2024-06-01 03:36:37Z\", 'error_codes': [700016], 'timestamp': '2024-06-01 03:36:37Z', 'trace_id': '66f7bffc-ea95-42f9-a58a-c93509898c00', 'correlation_id': '74ffddbb-c8c9-40d7-b7cf-a68c1552e9ac', 'error_uri': 'https://login.microsoftonline.com/error?code=700016'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  36:38.06 < b'+ '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'access_token'\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "##########     INITIATE IMAP FOR OUTLOOK ACCESS   ######################\n",
    "########################################################################\n",
    "imap = imaplib.IMAP4_SSL('outlook.office365.com')\n",
    "imap.debug = 4\n",
    "access_token = get_access_token()\n",
    "print(access_token)\n",
    "try:\n",
    "    imap.authenticate(\"XOAUTH2\", lambda x:generate_auth_string(\n",
    "      'gabriel.ayeni@imbank.co.ke',access_token['access_token']))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e8396ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m########################################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m##########     RETRIEVE UNREAD EMAILS/ATTACHMENT   #####################\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m########################################################################\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mimap\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minbox\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m status, email_ids \u001b[38;5;241m=\u001b[39m imap\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNSEEN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m email_ids \u001b[38;5;241m=\u001b[39m email_ids[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imap' is not defined"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "##########     RETRIEVE UNREAD EMAILS/ATTACHMENT   #####################\n",
    "########################################################################\n",
    "imap.select('inbox')\n",
    "status, email_ids = imap.search(None, 'UNSEEN')\n",
    "email_ids = email_ids[0].split()\n",
    "for email_id in email_ids:\n",
    "    status, email_data = imap.fetch(email_id, '(RFC822)')\n",
    "    for response in email_data:\n",
    "        if isinstance(response, tuple):\n",
    "            msg = email.message_from_bytes(response[1])\n",
    "            for part in msg.walk():\n",
    "                # Check if the part is an attachment\n",
    "                if part.get_content_type() == 'text/plain':\n",
    "                    body = part.get_payload(decode=True).decode()\n",
    "                if part.get_content_maintype() == 'multipart':\n",
    "                    continue\n",
    "                if part.get('Content-Disposition') is None:\n",
    "                    continue\n",
    "                # Save attachment to disk\n",
    "                filename = part.get_filename()\n",
    "                print(filename)\n",
    "                sender = msg['From']\n",
    "                subject = msg['Subject']\n",
    "                if '.png' not in filename:\n",
    "                    with open(filename, 'wb') as f:\n",
    "                        f.write(part.get_payload(decode=True))\n",
    "                #imap.store(email_id, '-FLAGS', '\\\\Seen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fd0499c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Obradley_Latest.xlsx'\n",
    "business_type = 'NON-SEASONAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c4b1a9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tm/qvqmw3jj2pz4m7hh0rj3z8w9_kzfyl/T/ipykernel_68896/1256712963.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  anchor_df.columns = anchor_df.columns.str.replace('[#,@,&,/,'']', '')\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "##########     READ ATTACHMENT RECEIVED.   #############################\n",
    "########################################################################\n",
    "if filename.split('.')[-1] == 'csv':\n",
    "    anchor_df=pd.read_csv(filename)\n",
    "else:\n",
    "    try:\n",
    "        anchor_df=pd.read_excel(filename,\n",
    "                                converters={'PHONE_NUMBER':str,\n",
    "                                           'REG_NO':str})\n",
    "    except:\n",
    "        anchor_df=pd.read_excel(filename,\n",
    "                               converters={'PHONE_NUMBER':str,\n",
    "                                           'REG_NO':str})\n",
    "anchor_df.columns = anchor_df.columns.str.replace('[#,@,&,/,'']', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "661ce2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'ANCHOR_CLIENT', 'SHOP_NAME', 'FULL_NAME_OF_DIRECTOR',\n",
       "       'AGENT_CODE', 'TOWN', 'PHONE_NUMBER', 'TOTAL', 'Month_1', 'Month_2',\n",
       "       'Month_3', 'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8',\n",
       "       'Month_9', 'Month_10', 'Month_11', 'Month_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "43b4f3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "afbcbdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>ANCHOR_CLIENT</th>\n",
       "      <th>SHOP_NAME</th>\n",
       "      <th>FULL_NAME_OF_DIRECTOR</th>\n",
       "      <th>AGENT_CODE</th>\n",
       "      <th>TOWN</th>\n",
       "      <th>PHONE_NUMBER</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Obradleys</td>\n",
       "      <td>JUJA BEAR STOCKIST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KE0132110</td>\n",
       "      <td>DGO-D04-A16-T082 - Githurai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77999760</td>\n",
       "      <td>6,927,445.56</td>\n",
       "      <td>6,927,445.57</td>\n",
       "      <td>6,927,445.58</td>\n",
       "      <td>6,927,445.59</td>\n",
       "      <td>6,927,445.60</td>\n",
       "      <td>6,927,445.61</td>\n",
       "      <td>6,927,445.62</td>\n",
       "      <td>6,927,445.63</td>\n",
       "      <td>6,927,445.64</td>\n",
       "      <td>6,927,445.65</td>\n",
       "      <td>6,927,445.66</td>\n",
       "      <td>6,927,445.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No ANCHOR_CLIENT           SHOP_NAME  FULL_NAME_OF_DIRECTOR AGENT_CODE  \\\n",
       "0     1     Obradleys  JUJA BEAR STOCKIST                    NaN  KE0132110   \n",
       "\n",
       "                          TOWN PHONE_NUMBER     TOTAL         Month_1  \\\n",
       "0  DGO-D04-A16-T082 - Githurai          NaN  77999760    6,927,445.56   \n",
       "\n",
       "          Month_2         Month_3         Month_4         Month_5  \\\n",
       "0    6,927,445.57    6,927,445.58    6,927,445.59    6,927,445.60   \n",
       "\n",
       "          Month_6         Month_7         Month_8         Month_9  \\\n",
       "0    6,927,445.61    6,927,445.62    6,927,445.63    6,927,445.64   \n",
       "\n",
       "         Month_10        Month_11        Month_12  \n",
       "0    6,927,445.65    6,927,445.66    6,927,445.67  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "88f4b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['TOTAL', 'Month_1', 'Month_2',\n",
    "       'Month_3', 'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8',\n",
    "       'Month_9', 'Month_10', 'Month_11', 'Month_12']\n",
    "for i in cols:\n",
    "    anchor_df[i] = [str(x).replace('\\xa0', '').replace(',','').strip() for x in anchor_df[i]]\n",
    "    anchor_df[i] = [float(x) for x in anchor_df[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ce1dc262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'ANCHOR_CLIENT', 'SHOP_NAME', 'FULL_NAME_OF_DIRECTOR',\n",
       "       'AGENT_CODE', 'TOWN', 'PHONE_NUMBER', 'TOTAL', 'Month_1', 'Month_2',\n",
       "       'Month_3', 'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8',\n",
       "       'Month_9', 'Month_10', 'Month_11', 'Month_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "808fd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_df.rename(columns={'ANCHOR CLIENT ':'ANCHOR_CLIENT',\n",
    "                         'NEAREST_LANDMARK (school churchmallbuilding e.t.c)': 'NEAREST_LANDMARK',\n",
    "                          'id no s': 'REG_NO',\n",
    "                         'REG_NO  (ID)': 'REG_NO', 'DEALER _NAME':'SHOP_NAME',\n",
    "                         'Total': 'TOTAL'},inplace=True)\n",
    "anchor_df['ANCHOR_CLIENT'] = anchor_df['ANCHOR_CLIENT'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6e0b7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del anchor_df['S.No']\n",
    "    del anchor_df['NO_OF_OUTLETS']\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ed95672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_df[['SHOP_NAME','ANCHOR_CLIENT', 'ROUTE', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
    "       'PHYSICAL_ADDRESS', 'TOWN', 'LOCATION', 'NEAREST_LANDMARK', 'REG_NO',\n",
    "       'PHONE_NUMBER']] = anchor_df[['SHOP_NAME','ANCHOR_CLIENT', 'ROUTE', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
    "       'PHYSICAL_ADDRESS', 'TOWN', 'LOCATION', 'NEAREST_LANDMARK', 'REG_NO',\n",
    "       'PHONE_NUMBER']].fillna('UNAVAILABLE')\n",
    "anchor_df=anchor_df.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2031bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_df[['SHOP_NAME','ANCHOR_CLIENT', 'ROUTE', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
    "       'PHYSICAL_ADDRESS', 'TOWN', 'LOCATION', 'NEAREST_LANDMARK', 'REG_NO',\n",
    "       'PHONE_NUMBER']] = anchor_df[['SHOP_NAME','ANCHOR_CLIENT', 'ROUTE', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
    "       'PHYSICAL_ADDRESS', 'TOWN', 'LOCATION', 'NEAREST_LANDMARK', 'REG_NO',\n",
    "       'PHONE_NUMBER']].replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8c3b41c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ANCHOR_CLIENT', 'SHOP_NAME', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
       "       'TOWN', 'PHONE_NUMBER', 'TOTAL', 'Month_1', 'Month_2', 'Month_3',\n",
       "       'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9',\n",
       "       'Month_10', 'Month_11', 'Month_12', 'ROUTE', 'PHYSICAL_ADDRESS',\n",
       "       'LOCATION', 'NEAREST_LANDMARK', 'REG_NO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_df = anchor_df[anchor_df['SHOP_NAME'] != 'UNAVAILABLE']\n",
    "anchor_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d930b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(anchor_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "615fc4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records will be inserted into this table:  Stock_Finance_Monthly\n"
     ]
    }
   ],
   "source": [
    "if 'Month_1' in cols:\n",
    "    table_name = 'Stock_Finance_Monthly'\n",
    "else:\n",
    "    table_name = 'Stock_Finance_Weekly'\n",
    "print('records will be inserted into this table: ', table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "294ecc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ANCHOR_CLIENT', 'SHOP_NAME', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
       "       'TOWN', 'PHONE_NUMBER', 'TOTAL', 'Month_1', 'Month_2', 'Month_3',\n",
       "       'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9',\n",
       "       'Month_10', 'Month_11', 'Month_12', 'ROUTE', 'PHYSICAL_ADDRESS',\n",
       "       'LOCATION', 'NEAREST_LANDMARK', 'REG_NO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "de6d2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a4ab4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_df['TOTAL'] = anchor_df['TOTAL'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2e703c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f9a760ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ANCHOR_CLIENT', 'SHOP_NAME', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
       "       'TOWN', 'PHONE_NUMBER', 'TOTAL', 'Month_1', 'Month_2', 'Month_3',\n",
       "       'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9',\n",
       "       'Month_10', 'Month_11', 'Month_12', 'ROUTE', 'PHYSICAL_ADDRESS',\n",
       "       'LOCATION', 'NEAREST_LANDMARK', 'REG_NO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "970444e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_df = anchor_df[['ANCHOR_CLIENT', 'SHOP_NAME', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
    "       'TOWN', 'PHONE_NUMBER','ROUTE', 'PHYSICAL_ADDRESS',\n",
    "       'LOCATION', 'NEAREST_LANDMARK', 'REG_NO', 'TOTAL', 'Month_1', 'Month_2', 'Month_3',\n",
    "       'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8', 'Month_9',\n",
    "       'Month_10', 'Month_11', 'Month_12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6a6619d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 27)\n",
      "  ANCHOR_CLIENT           SHOP_NAME FULL_NAME_OF_DIRECTOR AGENT_CODE  \\\n",
      "0     Obradleys  JUJA BEAR STOCKIST           UNAVAILABLE  KE0132110   \n",
      "\n",
      "                          TOWN PHONE_NUMBER        ROUTE PHYSICAL_ADDRESS  \\\n",
      "0  DGO-D04-A16-T082 - Githurai  UNAVAILABLE  UNAVAILABLE      UNAVAILABLE   \n",
      "\n",
      "      LOCATION NEAREST_LANDMARK  ...    Month_6    Month_7    Month_8  \\\n",
      "0  UNAVAILABLE      UNAVAILABLE  ... 6927445.61 6927445.62 6927445.63   \n",
      "\n",
      "     Month_9   Month_10   Month_11   Month_12   Forecast  Average_Forecast  \\\n",
      "0 6927445.64 6927445.65 6927445.66 6927445.67 6927000.00        6927000.00   \n",
      "\n",
      "   DATE_OF_REPORT  \n",
      "0      2024-06-21  \n",
      "\n",
      "[1 rows x 27 columns]\n",
      "end--- (1, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tm/qvqmw3jj2pz4m7hh0rj3z8w9_kzfyl/T/ipykernel_68896/396691524.py:43: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  new_df = pd.concat(fitted_list,0)\n",
      "/var/folders/tm/qvqmw3jj2pz4m7hh0rj3z8w9_kzfyl/T/ipykernel_68896/396691524.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_data.drop_duplicates(subset = ['SHOP_NAME'], keep='first',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "if business_type.upper() != 'SEASONAL':\n",
    "    if table_name == 'Stock_Finance_Monthly':\n",
    "        last_column = anchor_df.columns[-1]\n",
    "        last_month_index = last_column.split('_')[1]\n",
    "        transactions_amount = anchor_df.copy()\n",
    "        transactions_amount.drop(columns=['ROUTE', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
    "           'PHYSICAL_ADDRESS', 'TOWN', 'LOCATION', 'NEAREST_LANDMARK', 'REG_NO',\n",
    "           'PHONE_NUMBER','TOTAL','ANCHOR_CLIENT'],inplace=True)\n",
    "        refkey = 'SHOP_NAME'\n",
    "        transaction_week = transactions_amount.copy()\n",
    "        transaction_week = transaction_week.melt(id_vars=refkey,\n",
    "                             var_name='variable', \n",
    "                            value_name=\"value\")\n",
    "        format =\"%Y-%m-%d\"\n",
    "        transaction_week['value']=transaction_week['value'].apply(lambda x:str(x).replace(\"-\",'0').replace(' ','0'))\n",
    "        transaction_week['week_value']=transaction_week['value'].astype(float)\n",
    "        trans_data=transaction_week.fillna(0)\n",
    "        trans_data['value']=pd.to_numeric(trans_data['value']).replace(\"-\",0.0)\n",
    "        trans_data['week_value']=trans_data['week_value'].astype(float)\n",
    "        column_names=[]\n",
    "        for i in range(1,int(last_month_index) + 1,1):\n",
    "            column_names.append('Month_'+ str(i))\n",
    "        trans_data['variable'] = pd.Categorical(trans_data['variable'],\n",
    "                                            categories= column_names,ordered=True)\n",
    "        trans_data.sort_values(by = ['SHOP_NAME','variable'], inplace=True)\n",
    "        trans_data = trans_data[~trans_data['variable'].isnull()]\n",
    "        fitted_list = []\n",
    "        ########################################################################\n",
    "        ##########     APPLY SMOOTHING PER SHOP NAME   #########################\n",
    "        ########################################################################\n",
    "        for i in trans_data['SHOP_NAME'].unique():  \n",
    "            values = np.asarray(trans_data[trans_data['SHOP_NAME'] == i]['week_value'])\n",
    "            exp = SimpleExpSmoothing(values)#,**model) \n",
    "            exp_model = exp.fit(smoothing_level=0.56) \n",
    "            next_week_sales = exp_model.forecast(1)\n",
    "            result = exp_model.fittedvalues\n",
    "            df = pd.DataFrame(result)\n",
    "            df.columns=['ExpSmoothValues']\n",
    "            df['SHOP_NAME'] = i\n",
    "            df['Average_Value'] = np.mean(values)\n",
    "            df['Forecast'] = next_week_sales[0]\n",
    "            fitted_list.append(df)\n",
    "        new_df = pd.concat(fitted_list,0)\n",
    "        trans_data['ExpSmoothValues'] = new_df['ExpSmoothValues'].values\n",
    "        trans_data['Forecast'] = new_df['Forecast'].values\n",
    "        trans_data['Forecast'] = [round(x, -3) for x in trans_data['Forecast']]\n",
    "        trans_data['Average_Forecast'] = new_df['Average_Value'].values\n",
    "        trans_data['Average_Forecast'] = [round(x, -3) for x in trans_data['Average_Forecast']]\n",
    "        val_data = trans_data[['SHOP_NAME','Forecast','Average_Forecast']]\n",
    "        val_data.drop_duplicates(subset = ['SHOP_NAME'], keep='first',inplace=True)\n",
    "        val_data.reset_index(drop=True)\n",
    "        anchor_df = pd.merge(anchor_df,val_data,how='left',on='SHOP_NAME')\n",
    "        anchor_df['DATE_OF_REPORT'] = datetime.today().strftime('%Y-%m-%d')\n",
    "        anchor_df['DATE_OF_REPORT'] = pd.to_datetime(anchor_df['DATE_OF_REPORT'])\n",
    "        cols = list(anchor_df.columns)\n",
    "        ########################################################################\n",
    "        ##########WRITE THE DATA INTO ORACLE TABLE #############################\n",
    "        ########################################################################\n",
    "        writer = DataMigration()\n",
    "        writer.writePandas(table_name=table_name,columns=cols,\n",
    "                       sourcedataframe=anchor_df)\n",
    "    else:\n",
    "        last_column = anchor_df.columns[-1]\n",
    "        last_month_index = last_column.split('_')[1]\n",
    "        transactions_amount = anchor_df.copy()\n",
    "        transactions_amount.drop(columns=['ROUTE', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
    "           'PHYSICAL_ADDRESS', 'TOWN', 'LOCATION', 'NEAREST_LANDMARK', 'REG_NO',\n",
    "           'PHONE_NUMBER','TOTAL','ANCHOR_CLIENT'],inplace=True)\n",
    "        refkey = 'SHOP_NAME'\n",
    "        transaction_week = transactions_amount.copy()\n",
    "        transaction_week = transaction_week.melt(id_vars=refkey,\n",
    "                             var_name='variable', \n",
    "                            value_name=\"value\")\n",
    "        format =\"%Y-%m-%d\"\n",
    "        transaction_week['value']=transaction_week['value'].apply(lambda x:str(x).replace(\"-\",'0'))\n",
    "        transaction_week['week_value']=transaction_week['value'].astype(float)\n",
    "        trans_data=transaction_week.fillna(0)\n",
    "        trans_data['value']=pd.to_numeric(trans_data['value']).replace(\"-\",0.0)\n",
    "        trans_data['week_value']=trans_data['week_value'].astype(float)\n",
    "        column_names=[]\n",
    "        for i in range(1,int(last_month_index) + 1,1):\n",
    "            column_names.append('Week_'+ str(i))\n",
    "        trans_data['variable'] = pd.Categorical(trans_data['variable'],\n",
    "                                            categories= column_names,ordered=True)\n",
    "        trans_data.sort_values(by = ['SHOP_NAME','variable'], inplace=True)\n",
    "        trans_data = trans_data[~trans_data['variable'].isnull()]\n",
    "        fitted_list = []\n",
    "        ########################################################################\n",
    "        ##########     APPLY SMOOTHING PER SHOP NAME   #########################\n",
    "        ########################################################################\n",
    "        for i in trans_data['SHOP_NAME'].unique():  \n",
    "            values = np.asarray(trans_data[trans_data['SHOP_NAME'] == i]['week_value'])\n",
    "            exp = SimpleExpSmoothing(values)#,**model) \n",
    "            exp_model = exp.fit(smoothing_level=0.56) \n",
    "            next_week_sales = exp_model.forecast(1)\n",
    "            result = exp_model.fittedvalues\n",
    "            df = pd.DataFrame(result)\n",
    "            df.columns=['ExpSmoothValues']\n",
    "            df['SHOP_NAME'] = i\n",
    "            df['Average_Value'] = np.mean(values)\n",
    "            df['Forecast'] = next_week_sales[0]\n",
    "            fitted_list.append(df)\n",
    "        new_df = pd.concat(fitted_list,0)\n",
    "        trans_data['ExpSmoothValues'] = new_df['ExpSmoothValues'].values\n",
    "        trans_data['Forecast'] = new_df['Forecast'].values\n",
    "        trans_data['Forecast'] = [round(x, -3) for x in trans_data['Forecast']]\n",
    "        trans_data['Average_Forecast'] = new_df['Average_Value'].values\n",
    "        trans_data['Average_Forecast'] = [round(x, -3) for x in trans_data['Average_Forecast']]\n",
    "        val_data = trans_data[['SHOP_NAME','Forecast','Average_Forecast']]\n",
    "        val_data.drop_duplicates(subset = ['SHOP_NAME'], keep='first',inplace=True)\n",
    "        val_data.reset_index(drop=True)\n",
    "        anchor_df = pd.merge(anchor_df,val_data,how='left',on='SHOP_NAME')\n",
    "        anchor_df['DATE_OF_REPORT'] = datetime.today().strftime('%Y-%m-%d')\n",
    "        anchor_df['DATE_OF_REPORT'] = pd.to_datetime(anchor_df['DATE_OF_REPORT'])\n",
    "        cols = list(anchor_df.columns)\n",
    "        ########################################################################\n",
    "        ##########WRITE THE DATA INTO ORACLE TABLE #############################\n",
    "        ########################################################################\n",
    "        writer = DataMigration()\n",
    "        writer.writePandas(table_name=table_name,columns=cols,\n",
    "                       sourcedataframe=anchor_df)\n",
    "else:\n",
    "    print('Business type is {}'.format(business_type))\n",
    "    if table_name == 'Stock_Finance_Monthly':\n",
    "        last_column = anchor_df.columns[-1]\n",
    "        last_month_index = last_column.split('_')[1]\n",
    "        transactions_amount = anchor_df.copy()\n",
    "        transactions_amount.drop(columns=['ROUTE', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
    "           'PHYSICAL_ADDRESS', 'TOWN', 'LOCATION', 'NEAREST_LANDMARK', 'REG_NO',\n",
    "           'PHONE_NUMBER','TOTAL','ANCHOR_CLIENT'],inplace=True)\n",
    "        refkey = 'SHOP_NAME'\n",
    "        transaction_week = transactions_amount.copy()\n",
    "        transaction_week = transaction_week.melt(id_vars=refkey,\n",
    "                             var_name='variable', \n",
    "                            value_name=\"value\")\n",
    "        format =\"%Y-%m-%d\"\n",
    "        transaction_week['value']=transaction_week['value'].apply(lambda x:str(x).replace(\"-\",'0'))\n",
    "        transaction_week['week_value']=transaction_week['value'].replace(',','').astype(float)\n",
    "        trans_data=transaction_week.fillna(0)\n",
    "        trans_data['value']=pd.to_numeric(trans_data['value']).replace(\"-\",0.0)\n",
    "        trans_data['week_value']=trans_data['week_value'].astype(float)\n",
    "        column_names=[]\n",
    "        for i in range(1,int(last_month_index) + 1,1):\n",
    "            column_names.append('Month_'+ str(i))\n",
    "        trans_data['variable'] = pd.Categorical(trans_data['variable'],\n",
    "                                            categories= column_names,ordered=True)\n",
    "        trans_data.sort_values(by = ['SHOP_NAME','variable'], inplace=True)\n",
    "        trans_data = trans_data[~trans_data['variable'].isnull()]\n",
    "        fitted_list = []\n",
    "        ########################################################################\n",
    "        ##########     APPLY SMOOTHING PER SHOP NAME   #########################\n",
    "        ########################################################################\n",
    "        for i in trans_data['SHOP_NAME'].unique():\n",
    "            if (trans_data[(trans_data['SHOP_NAME'] == i) & (trans_data['week_value'] > 0)].shape[0]) < 6:\n",
    "                df = pd.DataFrame([0])\n",
    "                df.columns=['ExpSmoothValues']\n",
    "                df['SHOP_NAME'] = i\n",
    "                df['Average_Value'] = 0\n",
    "                df['Forecast'] = 0\n",
    "            else:   \n",
    "                values = np.asarray(trans_data[(trans_data['SHOP_NAME'] == i) & (trans_data['week_value'] > 0)]['week_value'])\n",
    "                exp = SimpleExpSmoothing(values)#,**model) \n",
    "                exp_model = exp.fit(smoothing_level=0.56)\n",
    "                next_week_sales = exp_model.forecast(1)\n",
    "                result = exp_model.fittedvalues\n",
    "                df = pd.DataFrame(result)\n",
    "                df.columns=['ExpSmoothValues']\n",
    "                df['SHOP_NAME'] = i\n",
    "                df['Average_Value'] = np.mean(values)\n",
    "                df['Forecast'] = next_week_sales[0]\n",
    "            fitted_list.append(df)\n",
    "        new_df = pd.concat(fitted_list,0)\n",
    "        for j in new_df['SHOP_NAME'].unique():\n",
    "            trans_data.loc[trans_data['SHOP_NAME'] == j,'Forecast'] = new_df[new_df['SHOP_NAME'] == j]['Forecast'].iloc[0]\n",
    "            trans_data['Forecast'] = [round(x, -3) for x in trans_data['Forecast']]\n",
    "            trans_data.loc[trans_data['SHOP_NAME'] == j,'Average_Forecast'] = new_df[new_df['SHOP_NAME'] == j]['Average_Value'].iloc[0]\n",
    "            trans_data['Average_Forecast'] = [round(x, -3) for x in trans_data['Average_Forecast']]\n",
    "        val_data = trans_data[['SHOP_NAME','Forecast','Average_Forecast']]\n",
    "        val_data.drop_duplicates(subset = ['SHOP_NAME'], keep='first',inplace=True)\n",
    "        val_data.reset_index(drop=True)\n",
    "        anchor_df = pd.merge(anchor_df,val_data,how='left',on='SHOP_NAME')\n",
    "        anchor_df['DATE_OF_REPORT'] = datetime.today().strftime('%Y-%m-%d')\n",
    "        anchor_df['DATE_OF_REPORT'] = pd.to_datetime(anchor_df['DATE_OF_REPORT'])\n",
    "        cols = list(anchor_df.columns)\n",
    "        ########################################################################\n",
    "        ##########WRITE THE DATA INTO ORACLE TABLE #############################\n",
    "        ########################################################################\n",
    "        writer = DataMigration()\n",
    "        writer.writePandas(table_name=table_name,columns=cols,\n",
    "                       sourcedataframe=anchor_df)\n",
    "    else:\n",
    "        last_column = anchor_df.columns[-1]\n",
    "        last_month_index = last_column.split('_')[1]\n",
    "        transactions_amount = anchor_df.copy()\n",
    "        transactions_amount.drop(columns=['ROUTE', 'FULL_NAME_OF_DIRECTOR', 'AGENT_CODE',\n",
    "           'PHYSICAL_ADDRESS', 'TOWN', 'LOCATION', 'NEAREST_LANDMARK', 'REG_NO',\n",
    "           'PHONE_NUMBER','TOTAL','ANCHOR_CLIENT'],inplace=True)\n",
    "        refkey = 'SHOP_NAME'\n",
    "        transaction_week = transactions_amount.copy()\n",
    "        transaction_week = transaction_week.melt(id_vars=refkey,\n",
    "                             var_name='variable', \n",
    "                            value_name=\"value\")\n",
    "        format =\"%Y-%m-%d\"\n",
    "        transaction_week['value']=transaction_week['value'].apply(lambda x:str(x).replace(\"-\",'0'))\n",
    "        transaction_week['week_value']=transaction_week['value'].replace(',','').astype(float)\n",
    "        trans_data=transaction_week.fillna(0)\n",
    "        trans_data['value']=pd.to_numeric(trans_data['value']).replace(\"-\",0.0)\n",
    "        trans_data['week_value']=trans_data['week_value'].astype(float)\n",
    "        column_names=[]\n",
    "        for i in range(1,int(last_month_index) + 1,1):\n",
    "            column_names.append('Week_'+ str(i))\n",
    "        trans_data['variable'] = pd.Categorical(trans_data['variable'],\n",
    "                                            categories= column_names,ordered=True)\n",
    "        trans_data.sort_values(by = ['SHOP_NAME','variable'], inplace=True)\n",
    "        trans_data = trans_data[~trans_data['variable'].isnull()]\n",
    "        fitted_list = []\n",
    "        ########################################################################\n",
    "        ##########     APPLY SMOOTHING PER SHOP NAME   #########################\n",
    "        ########################################################################\n",
    "        for i in trans_data['SHOP_NAME'].unique():\n",
    "            if (trans_data[(trans_data['SHOP_NAME'] == i) & (trans_data['week_value'] > 0)].shape[0]) < 15:\n",
    "                df = pd.DataFrame([0])\n",
    "                df.columns=['ExpSmoothValues']\n",
    "                df['SHOP_NAME'] = i\n",
    "                df['Average_Value'] = 0\n",
    "                df['Forecast'] = 0\n",
    "            else:   \n",
    "                values = np.asarray(trans_data[(trans_data['SHOP_NAME'] == i) & (trans_data['week_value'] > 0)]['week_value'])\n",
    "                exp = SimpleExpSmoothing(values)#,**model) \n",
    "                exp_model = exp.fit(smoothing_level=0.56)\n",
    "                next_week_sales = exp_model.forecast(1)\n",
    "                result = exp_model.fittedvalues\n",
    "                df = pd.DataFrame(result)\n",
    "                df.columns=['ExpSmoothValues']\n",
    "                df['SHOP_NAME'] = i\n",
    "                df['Average_Value'] = np.mean(values)\n",
    "                df['Forecast'] = next_week_sales[0]\n",
    "            fitted_list.append(df)\n",
    "        new_df = pd.concat(fitted_list,0)\n",
    "        for j in new_df['SHOP_NAME'].unique():\n",
    "            trans_data.loc[trans_data['SHOP_NAME'] == j,'Forecast'] = new_df[new_df['SHOP_NAME'] == j]['Forecast'].iloc[0]\n",
    "            trans_data['Forecast'] = [round(x, -3) for x in trans_data['Forecast']]\n",
    "            trans_data.loc[trans_data['SHOP_NAME'] == j,'Average_Forecast'] = new_df[new_df['SHOP_NAME'] == j]['Average_Value'].iloc[0]\n",
    "            trans_data['Average_Forecast'] = [round(x, -3) for x in trans_data['Average_Forecast']]\n",
    "        val_data = trans_data[['SHOP_NAME','Forecast','Average_Forecast']]\n",
    "        val_data.drop_duplicates(subset = ['SHOP_NAME'], keep='first',inplace=True)\n",
    "        val_data.reset_index(drop=True)\n",
    "        anchor_df = pd.merge(anchor_df,val_data,how='left',on='SHOP_NAME')\n",
    "        anchor_df['DATE_OF_REPORT'] = datetime.today().strftime('%Y-%m-%d')\n",
    "        anchor_df['DATE_OF_REPORT'] = pd.to_datetime(anchor_df['DATE_OF_REPORT'])\n",
    "        cols = list(anchor_df.columns)\n",
    "        ########################################################################\n",
    "        ##########WRITE THE DATA INTO ORACLE TABLE #############################\n",
    "        ########################################################################\n",
    "        writer = DataMigration()\n",
    "        writer.writePandas(table_name=table_name,columns=cols,\n",
    "                       sourcedataframe=anchor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1740f9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tm/qvqmw3jj2pz4m7hh0rj3z8w9_kzfyl/T/ipykernel_68896/3295390756.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query,connection)\n"
     ]
    }
   ],
   "source": [
    "import oracledb\n",
    "import pandas as pd\n",
    "connection = oracledb.connect(user='analytics', password='icub3pr0d2018#', dsn='192.168.202.75:1521/icubeprd')\n",
    "query = f\"\"\"select * from analytics.{table_name} where ANCHOR_CLIENT = '{anchor_df['ANCHOR_CLIENT'].iloc[0]}'\n",
    "and TO_CHAR(DATE_OF_REPORT,'MM/DD/YYYY') = TO_CHAR(SYSDATE,'MM/DD/YYYY')\"\"\"\n",
    "df = pd.read_sql_query(query,connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ff218b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "943ab850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHOP_NAME</th>\n",
       "      <th>ROUTE</th>\n",
       "      <th>FULL_NAME_OF_DIRECTOR</th>\n",
       "      <th>AGENT_CODE</th>\n",
       "      <th>PHYSICAL_ADDRESS</th>\n",
       "      <th>TOWN</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>NEAREST_LANDMARK</th>\n",
       "      <th>REG_NO</th>\n",
       "      <th>PHONE_NUMBER</th>\n",
       "      <th>...</th>\n",
       "      <th>MONTH_7</th>\n",
       "      <th>MONTH_8</th>\n",
       "      <th>MONTH_9</th>\n",
       "      <th>MONTH_10</th>\n",
       "      <th>MONTH_11</th>\n",
       "      <th>MONTH_12</th>\n",
       "      <th>DATE_OF_REPORT</th>\n",
       "      <th>FORECAST</th>\n",
       "      <th>AVERAGE_FORECAST</th>\n",
       "      <th>ANCHOR_CLIENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JUJA BEAR STOCKIST</td>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>KE0132110</td>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>DGO-D04-A16-T082 - Githurai</td>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>...</td>\n",
       "      <td>6927445.62</td>\n",
       "      <td>6927445.63</td>\n",
       "      <td>6927445.64</td>\n",
       "      <td>6927445.65</td>\n",
       "      <td>6927445.66</td>\n",
       "      <td>6927445.67</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>6927000</td>\n",
       "      <td>6927000</td>\n",
       "      <td>Obradleys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SHOP_NAME        ROUTE FULL_NAME_OF_DIRECTOR AGENT_CODE  \\\n",
       "0  JUJA BEAR STOCKIST  UNAVAILABLE           UNAVAILABLE  KE0132110   \n",
       "\n",
       "  PHYSICAL_ADDRESS                         TOWN     LOCATION NEAREST_LANDMARK  \\\n",
       "0      UNAVAILABLE  DGO-D04-A16-T082 - Githurai  UNAVAILABLE      UNAVAILABLE   \n",
       "\n",
       "        REG_NO PHONE_NUMBER  ...    MONTH_7    MONTH_8    MONTH_9   MONTH_10  \\\n",
       "0  UNAVAILABLE  UNAVAILABLE  ... 6927445.62 6927445.63 6927445.64 6927445.65   \n",
       "\n",
       "    MONTH_11   MONTH_12  DATE_OF_REPORT  FORECAST  AVERAGE_FORECAST  \\\n",
       "0 6927445.66 6927445.67      2024-06-21   6927000           6927000   \n",
       "\n",
       "   ANCHOR_CLIENT  \n",
       "0      Obradleys  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "25fb0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{anchor_df['ANCHOR_CLIENT'].iloc[0]}_{anchor_df['DATE_OF_REPORT'].iloc[0]}.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
